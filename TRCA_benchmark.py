import numpy as np
import scipy.io
import scipy.signal
import scipy.linalg
from scipy import stats
import warnings
from datetime import datetime
import os

def filterbank(eeg, fs, idx_fb):
    """
    Filter bank design for decomposing EEG data into sub-band components

    Parameters:
    -----------
    eeg : ndarray
        Input EEG data (n_channels, n_samples, n_trials)
    fs : float
        Sampling rate
    idx_fb : int
        Index of filters in filter bank analysis (1-10)

    Returns:
    --------
    y : ndarray
        Sub-band components decomposed by filter bank
    """
    if idx_fb is None:
        warnings.warn('Missing filter index. Default value (idx_fb = 1) will be used.')
        idx_fb = 1
    elif idx_fb < 1 or idx_fb > 10:
        raise ValueError('The number of sub-bands must be 0 < idx_fb <= 10.')

    # Get data dimensions
    if eeg.ndim == 2:
        num_chans, num_smpls = eeg.shape
        num_trials = 1
        eeg = eeg[:, :, np.newaxis]
    else:
        num_chans, num_smpls, num_trials = eeg.shape

    # Nyquist frequency - æ³¨æ„åŸå§‹ä»£ç ä¸­çš„fs=fs/2
    fs_nyq = fs / 2

    # Filter bank parameters
    passband = np.array([6, 14, 22, 30, 38, 46, 54, 62, 70, 78])
    stopband = np.array([4, 10, 16, 24, 32, 40, 48, 56, 64, 72])

    # Filter design parameters (æ³¨æ„ï¼šMATLABç´¢å¼•ä»1å¼€å§‹ï¼ŒPythonä»0å¼€å§‹)
    Wp = [passband[idx_fb - 1] / fs_nyq, 90 / fs_nyq]
    Ws = [stopband[idx_fb - 1] / fs_nyq, 100 / fs_nyq]

    # Design Chebyshev Type I filter
    N, Wn = scipy.signal.cheb1ord(Wp, Ws, 3, 40)
    B, A = scipy.signal.cheby1(N, 0.5, Wn, btype='band')

    # Apply filter
    y = np.zeros_like(eeg)
    if num_trials == 1:
        for ch_i in range(num_chans):
            y[ch_i, :, 0] = scipy.signal.filtfilt(B, A, eeg[ch_i, :, 0])
    else:
        for trial_i in range(num_trials):
            for ch_i in range(num_chans):
                y[ch_i, :, trial_i] = scipy.signal.filtfilt(B, A, eeg[ch_i, :, trial_i])

    # Remove singleton dimension if only one trial
    if num_trials == 1:
        y = y[:, :, 0]

    return y


def ftrca(eeg):
    """
    Fast Task-Related Component Analysis (fTRCA)

    Parameters:
    -----------
    eeg : ndarray
        Input EEG data (n_channels, n_samples, n_trials)

    Returns:
    --------
    W : ndarray
        Weight coefficients for spatial filtering
    """
    num_chans, num_smpls, num_trials = eeg.shape

    # Center data (remove mean)
    for trial_i in range(num_trials):
        x1 = eeg[:, :, trial_i]
        eeg[:, :, trial_i] = x1 - np.mean(x1, axis=1, keepdims=True)

    # Compute covariance matrices
    SX = np.sum(eeg, axis=2)
    S = SX @ SX.T

    UX = eeg.reshape(num_chans, num_smpls * num_trials)
    Q = UX @ UX.T

    # Solve generalized eigenvalue problem
    eigenvalues, W = scipy.linalg.eigh(S, Q)

    # Sort in descending order
    idx = np.argsort(eigenvalues)[::-1]
    W = W[:, idx]

    return W


def trca(eeg):
    """
    Task-Related Component Analysis (TRCA)

    Parameters:
    -----------
    eeg : ndarray
        Input EEG data (n_channels, n_samples, n_trials)

    Returns:
    --------
    W : ndarray
        Weight coefficients for spatial filtering
    """
    num_chans, num_smpls, num_trials = eeg.shape
    S = np.zeros((num_chans, num_chans))

    # Compute inter-trial covariance
    for trial_i in range(num_trials - 1):
        x1 = eeg[:, :, trial_i]
        x1 = x1 - np.mean(x1, axis=1, keepdims=True)

        for trial_j in range(trial_i + 1, num_trials):
            x2 = eeg[:, :, trial_j]
            x2 = x2 - np.mean(x2, axis=1, keepdims=True)
            S = S + x1 @ x2.T + x2 @ x1.T

    # Compute total covariance
    UX = eeg.reshape(num_chans, num_smpls * num_trials)
    UX = UX - np.mean(UX, axis=1, keepdims=True)
    Q = UX @ UX.T

    # Solve generalized eigenvalue problem
    eigenvalues, W = scipy.linalg.eigh(S, Q)

    # Sort in descending order
    idx = np.argsort(eigenvalues)[::-1]
    W = W[:, idx]

    return W


def sscor(eeg):
    """
    Sum of Squared Correlations (SSCOR)

    Parameters:
    -----------
    eeg : ndarray
        Input EEG data (n_channels, n_samples, n_trials)

    Returns:
    --------
    W : ndarray
        Weight coefficients for spatial filtering
    """
    num_chans, _, num_trials = eeg.shape

    # Compute average template
    X_n = np.mean(eeg, axis=2)
    X_n = X_n - np.mean(X_n, axis=1, keepdims=True)

    # Cholesky decomposition
    K_1 = np.linalg.cholesky(X_n @ X_n.T)

    # Compute sum of squared correlations
    G_T_G = np.zeros((num_chans, num_chans))
    for trial_i in range(num_trials):
        x_i = eeg[:, :, trial_i]
        x_i = x_i - np.mean(x_i, axis=1, keepdims=True)

        K_i = np.linalg.cholesky(x_i @ x_i.T)
        C_1i = X_n @ x_i.T
        G_i = np.linalg.solve(K_1.T, C_1i) @ np.linalg.inv(K_i)
        G_T_G = G_T_G + G_i.T @ G_i

    # Get largest eigenvector
    eigenvalues, eigenvectors = np.linalg.eigh(G_T_G)
    v_1 = eigenvectors[:, -1]

    # Compute spatial filter
    W = np.linalg.solve(K_1, v_1.reshape(-1, 1))

    return W


def itr(n, p, t):
    """
    Calculate information transfer rate (ITR) for BCI

    Parameters:
    -----------
    n : int
        Number of targets
    p : float
        Target identification accuracy (0 <= p <= 1)
    t : float
        Averaged time for a selection [s]

    Returns:
    --------
    itr : float
        Information transfer rate [bits/min]
    """
    if p < 0 or p > 1:
        raise ValueError('Accuracy needs to be between 0 and 1.')
    elif p < 1 / n:
        warnings.warn('The ITR might be incorrect because accuracy < chance level.')
        return 0
    elif p == 1:
        return np.log2(n) * 60 / t
    else:
        return (np.log2(n) + p * np.log2(p) + (1 - p) * np.log2((1 - p) / (n - 1))) * 60 / t


def train_model(eeg, fs, num_fbs, algorithm='ftrca'):
    """
    Training model based on template-matching method for SSVEP detection

    Parameters:
    -----------
    eeg : ndarray
        Input EEG data (n_targets, n_channels, n_samples, n_trials)
    fs : float
        Sampling rate
    num_fbs : int
        Number of sub-bands
    algorithm : str
        Spatial filtering method ('ftrca', 'trca', or 'sscor')

    Returns:
    --------
    model : dict
        Learning model for testing phase
    """
    if algorithm not in ['ftrca', 'trca', 'sscor']:
        raise ValueError('Algorithm should be selected from ftrca, trca, or sscor.')

    print(f'The algorithm, {algorithm}, will be used.')

    if num_fbs is None:
        num_fbs = 3

    num_targs, num_chans, num_smpls, _ = eeg.shape

    # Initialize arrays
    trains = np.zeros((num_targs, num_fbs, num_chans, num_smpls))
    W = np.zeros((num_fbs, num_targs, num_chans))

    # Train for each target and filter bank
    for targ_i in range(num_targs):
        eeg_tmp = eeg[targ_i, :, :, :]

        for fb_i in range(num_fbs):
            # Apply filter bank
            eeg_filtered = filterbank(eeg_tmp, fs, fb_i + 1)  # MATLABç´¢å¼•ä»1å¼€å§‹

            # Store average template
            trains[targ_i, fb_i, :, :] = np.mean(eeg_filtered, axis=2)

            # Compute spatial filter
            if algorithm == 'ftrca':
                w_tmp = ftrca(eeg_filtered)
            elif algorithm == 'trca':
                w_tmp = trca(eeg_filtered)
            elif algorithm == 'sscor':
                w_tmp = sscor(eeg_filtered)

            W[fb_i, targ_i, :] = w_tmp[:, 0]

    # Create model dictionary
    model = {
        'trains': trains,
        'W': W,
        'num_fbs': num_fbs,
        'fs': fs,
        'num_targs': num_targs
    }

    return model


def test_model(eeg, model, is_ensemble=True):
    """
    Test model based on template-matching method for SSVEP detection

    Parameters:
    -----------
    eeg : ndarray
        Input EEG data (n_targets, n_channels, n_samples)
    model : dict
        Learning model from training phase
    is_ensemble : bool
        True for ensemble TRCA method, False for standard TRCA

    Returns:
    --------
    results : ndarray
        Estimated target indices (1-based to match MATLAB)
    """
    num_targs = model['num_targs']
    num_fbs = model['num_fbs']

    # Filter bank coefficients
    fb_coefs = np.arange(1, num_fbs + 1) ** (-1.25) + 0.25

    results = np.zeros(num_targs, dtype=int)

    for targ_i in range(num_targs):
        test_tmp = eeg[targ_i, :, :]
        r = np.zeros((num_fbs, num_targs))

        for fb_i in range(num_fbs):
            # Apply filter bank
            testdata = filterbank(test_tmp, model['fs'], fb_i + 1)

            for class_i in range(num_targs):
                traindata = model['trains'][class_i, fb_i, :, :]

                if not is_ensemble:
                    # Standard TRCA: use class-specific spatial filter
                    w = model['W'][fb_i, class_i, :]
                else:
                    # Ensemble TRCA: average spatial filters across all classes
                    w = np.mean(model['W'][fb_i, :, :], axis=0)

                # Compute correlation
                r_tmp = np.corrcoef(testdata.T @ w, traindata.T @ w)
                r[fb_i, class_i] = r_tmp[0, 1]

        # Weighted combination across filter banks
        rho = fb_coefs @ r

        # Find maximum (add 1 for MATLAB-style indexing)
        results[targ_i] = np.argmax(rho) + 1

    return results


# ==================== æ–°å¢åŠŸèƒ½ï¼šæ¨¡å‹ä¿å­˜å’ŒåŠ è½½ ====================

def save_trca_pretrained_weights(model, filename='trca_pretrained_weights.mat', subject_id=1):
    """
    ä¿å­˜TRCAæ¨¡å‹ä¸ºé¢„è®­ç»ƒæƒé‡æ–‡ä»¶
    
    Parameters:
    -----------
    model : dict
        è®­ç»ƒå¥½çš„TRCAæ¨¡å‹
    filename : str
        ä¿å­˜çš„æ–‡ä»¶å
    subject_id : int
        è¢«è¯•ç¼–å·
    """
    
    print(f"æ­£åœ¨ä¿å­˜TRCAé¢„è®­ç»ƒæƒé‡åˆ°: {filename}")
    
    # è®¡ç®—ensembleæƒé‡ï¼ˆæ¯ä¸ªå­é¢‘å¸¦çš„å¹³å‡æƒé‡ï¼‰
    ensemble_weights = {}
    for fb_i in range(model['num_fbs']):
        # å¯¹æ¯ä¸ªå­é¢‘å¸¦ï¼Œè®¡ç®—æ‰€æœ‰ç›®æ ‡çš„å¹³å‡ç©ºé—´æ»¤æ³¢å™¨
        ensemble_w = np.mean(model['W'][fb_i, :, :], axis=0)
        ensemble_weights[f'W_ensemble_band{fb_i+1}'] = ensemble_w.reshape(-1, 1)
    
    # åˆ†ç¦»æ¯ä¸ªå­é¢‘å¸¦çš„è®­ç»ƒæ¨¡æ¿
    templates = {}
    for fb_i in range(model['num_fbs']):
        templates[f'trains_band{fb_i+1}'] = model['trains'][:, fb_i, :, :]
    
    # åˆ†ç¦»æ¯ä¸ªå­é¢‘å¸¦çš„ç©ºé—´æ»¤æ³¢å™¨æƒé‡
    spatial_filters = {}
    for fb_i in range(model['num_fbs']):
        spatial_filters[f'W_band{fb_i+1}'] = model['W'][fb_i, :, :]
    
    # æ»¤æ³¢å™¨é“¶è¡Œç³»æ•°
    fb_coefs = np.arange(1, model['num_fbs'] + 1) ** (-1.25) + 0.25
    
    # æ„å»ºä¿å­˜çš„æ•°æ®å­—å…¸
    save_data = {
        # Ensembleæƒé‡ï¼ˆç”¨äºå®æ—¶è¯†åˆ«ï¼‰
        **ensemble_weights,
        
        # è®­ç»ƒæ¨¡æ¿ï¼ˆæ¯ä¸ªå­é¢‘å¸¦ï¼‰
        **templates,
        
        # å®Œæ•´çš„ç©ºé—´æ»¤æ³¢å™¨æƒé‡ï¼ˆæ¯ä¸ªå­é¢‘å¸¦Ã—æ¯ä¸ªç›®æ ‡ï¼‰
        **spatial_filters,
        
        # æ»¤æ³¢å™¨é“¶è¡Œç³»æ•°
        'fb_coefs': fb_coefs,
        
        # æ¨¡å‹å‚æ•°
        'fs': np.array([[model['fs']]]),
        'num_fbs': np.array([[model['num_fbs']]]),
        'num_targs': np.array([[model['num_targs']]]),
        
        # æ¨¡å‹ä¿¡æ¯
        'model_info': {
            'algorithm': 'ensemble_trca',
            'subject_id': subject_id,
            'save_time': datetime.now().isoformat(),
            'version': '1.0',
            'description': 'TRCA pretrained weights for single subject'
        }
    }
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = os.path.dirname(filename) if os.path.dirname(filename) else '.'
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    # ä¿å­˜ä¸ºMATLABæ ¼å¼
    try:
        scipy.io.savemat(filename, save_data)
        print(f"âœ… TRCAé¢„è®­ç»ƒæƒé‡ä¿å­˜æˆåŠŸ!")
        print(f"   æ–‡ä»¶ä½ç½®: {os.path.abspath(filename)}")
        print(f"   æ–‡ä»¶å¤§å°: {os.path.getsize(filename) / 1024:.2f} KB")
        
        # æ˜¾ç¤ºä¿å­˜çš„å†…å®¹æ‘˜è¦
        print(f"\nä¿å­˜å†…å®¹æ‘˜è¦:")
        print(f"- Ensembleæƒé‡: {model['num_fbs']} ä¸ªå­é¢‘å¸¦")
        print(f"- è®­ç»ƒæ¨¡æ¿: {model['num_targs']} ä¸ªç›®æ ‡ Ã— {model['num_fbs']} ä¸ªå­é¢‘å¸¦")
        print(f"- ç©ºé—´æ»¤æ³¢å™¨: {model['num_fbs']} Ã— {model['num_targs']} ä¸ªæƒé‡çŸ©é˜µ")
        print(f"- é‡‡æ ·ç‡: {model['fs']} Hz")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        return False


def load_trca_pretrained_weights(filename='trca_pretrained_weights.mat'):
    """
    åŠ è½½TRCAé¢„è®­ç»ƒæƒé‡æ–‡ä»¶
    
    Parameters:
    -----------
    filename : str
        æƒé‡æ–‡ä»¶å
        
    Returns:
    --------
    model : dict
        é‡å»ºçš„TRCAæ¨¡å‹
    """
    
    print(f"æ­£åœ¨åŠ è½½TRCAé¢„è®­ç»ƒæƒé‡: {filename}")
    
    try:
        # åŠ è½½MATLABæ–‡ä»¶
        data = scipy.io.loadmat(filename)
        
        # æå–åŸºæœ¬å‚æ•°
        fs = int(data['fs'][0, 0])
        num_fbs = int(data['num_fbs'][0, 0])
        num_targs = int(data['num_targs'][0, 0])
        
        # é‡å»ºtrainsæ•°ç»„
        trains = np.zeros((num_targs, num_fbs, data['trains_band1'].shape[1], data['trains_band1'].shape[2]))
        for fb_i in range(num_fbs):
            trains[:, fb_i, :, :] = data[f'trains_band{fb_i+1}']
        
        # é‡å»ºWæ•°ç»„
        W = np.zeros((num_fbs, num_targs, data['W_band1'].shape[1]))
        for fb_i in range(num_fbs):
            W[fb_i, :, :] = data[f'W_band{fb_i+1}']
        
        # é‡å»ºæ¨¡å‹å­—å…¸
        model = {
            'trains': trains,
            'W': W,
            'num_fbs': num_fbs,
            'fs': fs,
            'num_targs': num_targs
        }
        
        print(f"âœ… TRCAé¢„è®­ç»ƒæƒé‡åŠ è½½æˆåŠŸ!")
        print(f"   ç›®æ ‡æ•°é‡: {num_targs}")
        print(f"   å­é¢‘å¸¦æ•°é‡: {num_fbs}")
        print(f"   é‡‡æ ·ç‡: {fs} Hz")
        
        return model
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return None


def verify_model_save_load(original_model, filename):
    """
    éªŒè¯æ¨¡å‹ä¿å­˜å’ŒåŠ è½½çš„æ­£ç¡®æ€§
    
    Parameters:
    -----------
    original_model : dict
        åŸå§‹æ¨¡å‹
    filename : str
        ä¿å­˜çš„æ–‡ä»¶å
    """
    
    print("\n" + "="*50)
    print("éªŒè¯æ¨¡å‹ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½")
    print("="*50)
    
    # åŠ è½½ä¿å­˜çš„æ¨¡å‹
    loaded_model = load_trca_pretrained_weights(filename)
    
    if loaded_model is None:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•éªŒè¯")
        return False
    
    # éªŒè¯å…³é”®å‚æ•°
    checks = []
    
    # æ£€æŸ¥åŸºæœ¬å‚æ•°
    checks.append(('é‡‡æ ·ç‡', original_model['fs'] == loaded_model['fs']))
    checks.append(('å­é¢‘å¸¦æ•°é‡', original_model['num_fbs'] == loaded_model['num_fbs']))
    checks.append(('ç›®æ ‡æ•°é‡', original_model['num_targs'] == loaded_model['num_targs']))
    
    # æ£€æŸ¥æ•°ç»„å½¢çŠ¶
    checks.append(('trainså½¢çŠ¶', original_model['trains'].shape == loaded_model['trains'].shape))
    checks.append(('Wå½¢çŠ¶', original_model['W'].shape == loaded_model['W'].shape))
    
    # æ£€æŸ¥æ•°å€¼ç²¾åº¦ï¼ˆå…è®¸å°çš„æ•°å€¼è¯¯å·®ï¼‰
    trains_close = np.allclose(original_model['trains'], loaded_model['trains'], rtol=1e-10)
    W_close = np.allclose(original_model['W'], loaded_model['W'], rtol=1e-10)
    checks.append(('trainsæ•°å€¼', trains_close))
    checks.append(('Wæ•°å€¼', W_close))
    
    # æ˜¾ç¤ºéªŒè¯ç»“æœ
    all_passed = True
    for check_name, passed in checks:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{check_name:12} : {status}")
        all_passed = all_passed and passed
    
    print("\n" + "="*50)
    if all_passed:
        print("ğŸ‰ æ¨¡å‹ä¿å­˜å’ŒåŠ è½½éªŒè¯å®Œå…¨é€šè¿‡ï¼")
        print("   é¢„è®­ç»ƒæƒé‡æ–‡ä»¶å¯ä»¥å®‰å…¨ä½¿ç”¨ã€‚")
    else:
        print("âš ï¸  æ¨¡å‹ä¿å­˜å’ŒåŠ è½½å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ã€‚")
    print("="*50)
    
    return all_passed


def main():
    """
    Main function - Implementation of TRCA-based SSVEP detection with model saving
    """
    print("TRCA-based SSVEP Detection System with Model Saving")
    print("=" * 60)

    # Parameters for analysis
    filename = 'data/S1.mat'  # åªå¤„ç†S1è¢«è¯•
    len_gaze_s = 0.5 # Data length for target identification [s]
    len_delay_s = 0.13  # Visual latency [s]
    num_fbs = 5  # Number of sub-bands
    is_ensemble = 1  # 0: TRCA, 1: Ensemble TRCA
    alpha_ci = 0.05  # Significance level for confidence intervals

    # Fixed parameters
    fs = 250  # Sampling rate [Hz]
    len_shift_s = 0.5  # Duration for gaze shifting [s]

    # Stimulus frequencies
    list_freqs = []
    for offset in [0, 0.2, 0.4, 0.6, 0.8]:
        list_freqs.extend(np.arange(8, 16) + offset)
    list_freqs = np.array(list_freqs)

    num_targs = len(list_freqs)
    labels = np.arange(1, num_targs + 1)  # 1-based labels

    # Calculate derived parameters
    len_gaze_smpl = int(np.round(len_gaze_s * fs))
    len_delay_smpl = int(np.round(len_delay_s * fs))
    len_sel_s = len_gaze_s + len_shift_s
    ci = 100 * (1 - alpha_ci)

    # Load data
    print(f"\nåŠ è½½æ•°æ®: {filename}")
    try:
        mat_data = scipy.io.loadmat(filename)
        data = mat_data['data']  # Assuming variable name is 'data'

        # Rearrange dimensions: [channels, samples, targets, blocks] -> [targets, channels, samples, blocks]
        eeg = np.transpose(data, (2, 0, 1, 3))

        # Select channels of interest (convert MATLAB 1-based to Python 0-based)
        chan_idx = np.array([48, 54, 55, 56, 57, 58, 61, 62, 63]) - 1
        eeg = eeg[:, chan_idx, :, :]

        # Get data dimensions
        _, num_chans, _, num_blocks = eeg.shape

        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"   æ•°æ®å½¢çŠ¶: {eeg.shape}")
        print(f"   ä½¿ç”¨é€šé“æ•°: {num_chans}")
        print(f"   å®éªŒå—æ•°: {num_blocks}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # Perform Leave-One-Out Cross-Validation
    print(f"\nå¼€å§‹ {'Ensemble' if is_ensemble else 'Standard'} TRCA è®­ç»ƒå’Œæµ‹è¯•:")
    print("-" * 50)

    accs = np.zeros(num_blocks)
    itrs = np.zeros(num_blocks)
    trained_model = None  # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹

    for loocv_i in range(num_blocks):
        # Training stage
        train_idx = list(range(num_blocks))
        train_idx.remove(loocv_i)
        traindata = eeg[:, :, :, train_idx]

        model = train_model(traindata, fs, num_fbs, 'ftrca')
        
        # ä¿å­˜ç¬¬ä¸€æ¬¡è®­ç»ƒçš„æ¨¡å‹ç”¨äºåç»­ä¿å­˜
        if trained_model is None:
            trained_model = model

        # Test stage
        testdata = eeg[:, :, :, loocv_i]
        estimated = test_model(testdata, model, is_ensemble)

        # Evaluation
        is_correct = (estimated == labels)
        accs[loocv_i] = np.mean(is_correct) * 100
        itrs[loocv_i] = itr(num_targs, np.mean(is_correct), len_sel_s)

        print(f'Block {loocv_i + 1}: Accuracy = {accs[loocv_i]:5.2f}%, ITR = {itrs[loocv_i]:5.2f} bpm')

    # Summarize results
    print("\n" + "=" * 50)
    print("äº¤å‰éªŒè¯ç»“æœæ±‡æ€»")
    print("=" * 50)

    # Calculate confidence intervals
    acc_mean = np.mean(accs)
    acc_ci = stats.t.interval(1 - alpha_ci, len(accs) - 1, loc=acc_mean, scale=stats.sem(accs))

    itr_mean = np.mean(itrs)
    itr_ci = stats.t.interval(1 - alpha_ci, len(itrs) - 1, loc=itr_mean, scale=stats.sem(itrs))

    print(f'å¹³å‡å‡†ç¡®ç‡ = {acc_mean:5.2f}% ({ci:.0f}% CI: {acc_ci[0]:5.2f} - {acc_ci[1]:5.2f}%)')
    print(f'å¹³å‡ITR = {itr_mean:5.2f} bpm ({ci:.0f}% CI: {itr_ci[0]:5.2f} - {itr_ci[1]:5.2f} bpm)')

    # ========== æ–°å¢åŠŸèƒ½ï¼šä¿å­˜é¢„è®­ç»ƒæƒé‡ ==========
    print("\n" + "=" * 60)
    print("ä¿å­˜TRCAé¢„è®­ç»ƒæƒé‡")
    print("=" * 60)
    
    if trained_model is not None:
        # ä¿å­˜é¢„è®­ç»ƒæƒé‡
        weight_filename = 'trca_pretrained_weights.mat'
        subject_id = 1  # S1è¢«è¯•
        
        success = save_trca_pretrained_weights(trained_model, weight_filename, subject_id)
        
        if success:
            # éªŒè¯ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½
            verify_model_save_load(trained_model, weight_filename)
            
            print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
            print(f"   TRCAé¢„è®­ç»ƒæƒé‡å·²ä¿å­˜ä¸º: {weight_filename}")
            print(f"   ç°åœ¨å¯ä»¥åœ¨eeg_processor.pyä¸­åŠ è½½ä½¿ç”¨æ­¤æ¨¡å‹")
            print(f"   å¹³å‡è¯†åˆ«å‡†ç¡®ç‡: {acc_mean:.2f}%")
        else:
            print(f"\nâŒ é¢„è®­ç»ƒæƒé‡ä¿å­˜å¤±è´¥")
    else:
        print("âŒ æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¯ä»¥ä¿å­˜")


if __name__ == "__main__":
    main()